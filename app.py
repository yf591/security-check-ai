"""
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯AI - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
å–¶æ¥­å‘ã‘ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨ºæ–­æ”¯æ´ãƒ„ãƒ¼ãƒ«
"""

import os
import sys
from pathlib import Path
import logging
from datetime import datetime

import streamlit as st
import pandas as pd
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from src.document_processor import DocumentProcessor, process_directory
from src.vector_database import VectorDatabase, build_database_from_directory

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è¨­å®š
VECTORDB_PATH = os.getenv("VECTORDB_PATH", "./vectordb")
RAW_DATA_DIR = os.getenv("RAW_DATA_DIR", "./data/raw")
PROCESSED_DATA_DIR = os.getenv("PROCESSED_DATA_DIR", "./data/processed")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯AI",
    page_icon="ğŸ”’",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "vectordb" not in st.session_state:
    st.session_state.vectordb = None
if "qa_history" not in st.session_state:
    st.session_state.qa_history = []


def init_vectordb():
    """ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
    if st.session_state.vectordb is None:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            st.session_state.vectordb = VectorDatabase(
                persist_directory=VECTORDB_PATH, embedding_model=EMBEDDING_MODEL
            )
    return st.session_state.vectordb


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

    st.title("ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯AI")
    st.markdown("å–¶æ¥­å‘ã‘ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨ºæ–­æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ“š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ
        vectordb = init_vectordb()
        stats = vectordb.get_stats()

        st.metric("ç™»éŒ²æ¸ˆã¿Q&Aä»¶æ•°", stats["total_qa_pairs"])

        st.divider()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰")

        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["pdf", "docx", "xlsx", "xls", "txt", "csv"],
            accept_multiple_files=True,
            help="PDFã€Wordã€Excelã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ",
        )

        if uploaded_files:
            if st.button("ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦DBã«è¿½åŠ ", type="primary"):
                process_uploaded_files(uploaded_files, vectordb)

        st.divider()

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä¸€æ‹¬æ§‹ç¯‰
        if st.button("ğŸ”„ data/rawã‹ã‚‰å†æ§‹ç¯‰"):
            rebuild_database(vectordb)

        if stats["total_qa_pairs"] > 0:
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ä¸­..."):
                    vectordb.clear_database()
                    st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                    st.rerun()

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tab1, tab2, tab3 = st.tabs(["ğŸ” è³ªå•æ¤œç´¢", "ğŸ“ ä¸€æ‹¬è³ªå•å‡¦ç†", "ğŸ“Š å±¥æ­´"])

    with tab1:
        single_question_tab(vectordb)

    with tab2:
        batch_question_tab(vectordb)

    with tab3:
        history_tab()


def single_question_tab(vectordb: VectorDatabase):
    """å˜ä¸€è³ªå•ã‚¿ãƒ–"""
    st.header("è³ªå•ã‚’å…¥åŠ›")

    col1, col2 = st.columns([3, 1])

    with col1:
        query = st.text_area(
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            height=150,
            placeholder="ä¾‹: ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–æ–¹æ³•ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        )

    with col2:
        top_k = st.slider("æ¤œç´¢çµæœæ•°", 1, 10, 3)
        score_threshold = st.slider("é¡ä¼¼åº¦é–¾å€¤", 0.0, 1.0, 0.5, 0.05)

    if st.button("ğŸ” æ¤œç´¢", type="primary", disabled=not query):
        search_and_display(vectordb, query, top_k, score_threshold)


def batch_question_tab(vectordb: VectorDatabase):
    """ä¸€æ‹¬è³ªå•å‡¦ç†ã‚¿ãƒ–"""
    st.header("ä¸€æ‹¬è³ªå•å‡¦ç†")

    st.markdown(
        """
    è¤‡æ•°ã®è³ªå•ã‚’ä¸€åº¦ã«å‡¦ç†ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã§è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:
    - ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è³ªå•ã‚’å…¥åŠ›ï¼ˆ1è¡Œ1è³ªå•ï¼‰
    - CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè³ªå•åˆ—ã‚’å«ã‚€ï¼‰
    """
    )

    input_method = st.radio("å…¥åŠ›æ–¹æ³•", ["ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "CSVãƒ•ã‚¡ã‚¤ãƒ«"])

    questions = []

    if input_method == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        batch_text = st.text_area(
            "è³ªå•ã‚’å…¥åŠ›ï¼ˆ1è¡Œã«1ã¤ã®è³ªå•ï¼‰",
            height=200,
            placeholder="ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–æ–¹æ³•ã«ã¤ã„ã¦\nã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã®è¨­å®šæ–¹æ³•\n...",
        )
        if batch_text:
            questions = [q.strip() for q in batch_text.split("\n") if q.strip()]

    else:
        uploaded_file = st.file_uploader(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["csv"],
            help="è³ªå•ãŒå«ã¾ã‚Œã‚‹åˆ—ãŒã‚ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«",
        )

        if uploaded_file:
            df = pd.read_csv(uploaded_file)
            st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
            st.dataframe(df.head())

            question_col = st.selectbox("è³ªå•ãŒå«ã¾ã‚Œã‚‹åˆ—ã‚’é¸æŠ", df.columns)

            if question_col:
                questions = df[question_col].dropna().tolist()

    if questions:
        st.info(f"ğŸ“ {len(questions)}ä»¶ã®è³ªå•ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸ")

        col1, col2 = st.columns(2)
        with col1:
            top_k = st.slider("å„è³ªå•ã®æ¤œç´¢çµæœæ•°", 1, 5, 1, key="batch_topk")
        with col2:
            score_threshold = st.slider(
                "é¡ä¼¼åº¦é–¾å€¤", 0.0, 1.0, 0.6, 0.05, key="batch_threshold"
            )

        if st.button("ğŸš€ ä¸€æ‹¬æ¤œç´¢", type="primary"):
            batch_search_and_display(vectordb, questions, top_k, score_threshold)


def history_tab():
    """å±¥æ­´ã‚¿ãƒ–"""
    st.header("æ¤œç´¢å±¥æ­´")

    if not st.session_state.qa_history:
        st.info("ã¾ã æ¤œç´¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # å±¥æ­´ã‚’DataFrameã«å¤‰æ›
    history_df = pd.DataFrame(st.session_state.qa_history)

    st.dataframe(history_df, use_container_width=True, hide_index=True)

    # CSVå‡ºåŠ›
    if st.button("ğŸ“¥ å±¥æ­´ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
        csv = history_df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button(
            label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"security_check_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
        )

    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.qa_history = []
        st.rerun()


def search_and_display(
    vectordb: VectorDatabase, query: str, top_k: int, score_threshold: float
):
    """æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’è¡¨ç¤º"""
    with st.spinner("æ¤œç´¢ä¸­..."):
        results = vectordb.search(query, top_k=top_k, score_threshold=score_threshold)

    if not results:
        st.warning("è©²å½“ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è³ªå•ã‚’å¤‰ãˆã¦è©¦ã—ã¦ãã ã•ã„ã€‚")
        return

    st.success(f"âœ… {len(results)}ä»¶ã®å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

    for i, result in enumerate(results, 1):
        with st.expander(
            f"ğŸ“„ å›ç­” {i} - é¡ä¼¼åº¦: {result['score']:.2%}", expanded=(i == 1)
        ):
            st.markdown(f"**è³ªå•:** {result['question']}")
            st.markdown(f"**å›ç­”:**")
            st.info(result["answer"])
            st.caption(f"å‡ºå…¸: {result['source']}")

            # å±¥æ­´ã«è¿½åŠ 
            st.session_state.qa_history.append(
                {
                    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "æ¤œç´¢ã‚¯ã‚¨ãƒª": query,
                    "ãƒãƒƒãƒã—ãŸè³ªå•": result["question"],
                    "å›ç­”": result["answer"],
                    "é¡ä¼¼åº¦": f"{result['score']:.2%}",
                    "å‡ºå…¸": result["source"],
                }
            )


def batch_search_and_display(
    vectordb: VectorDatabase, questions: list, top_k: int, score_threshold: float
):
    """ä¸€æ‹¬æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    results_list = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, question in enumerate(questions):
        status_text.text(f"å‡¦ç†ä¸­: {i+1}/{len(questions)}")
        progress_bar.progress((i + 1) / len(questions))

        results = vectordb.search(
            question, top_k=top_k, score_threshold=score_threshold
        )

        if results:
            best_result = results[0]
            results_list.append(
                {
                    "è³ªå•": question,
                    "ãƒãƒƒãƒã—ãŸè³ªå•": best_result["question"],
                    "å›ç­”": best_result["answer"],
                    "é¡ä¼¼åº¦": f"{best_result['score']:.2%}",
                    "å‡ºå…¸": best_result["source"],
                }
            )

            # å±¥æ­´ã«è¿½åŠ 
            st.session_state.qa_history.append(
                {
                    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "æ¤œç´¢ã‚¯ã‚¨ãƒª": question,
                    "ãƒãƒƒãƒã—ãŸè³ªå•": best_result["question"],
                    "å›ç­”": best_result["answer"],
                    "é¡ä¼¼åº¦": f"{best_result['score']:.2%}",
                    "å‡ºå…¸": best_result["source"],
                }
            )
        else:
            results_list.append(
                {
                    "è³ªå•": question,
                    "ãƒãƒƒãƒã—ãŸè³ªå•": "è©²å½“ãªã—",
                    "å›ç­”": "è©²å½“ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                    "é¡ä¼¼åº¦": "0%",
                    "å‡ºå…¸": "-",
                }
            )

    status_text.empty()
    progress_bar.empty()

    st.success(f"âœ… {len(questions)}ä»¶ã®è³ªå•ã‚’å‡¦ç†ã—ã¾ã—ãŸ")

    # çµæœã‚’DataFrameã§è¡¨ç¤º
    results_df = pd.DataFrame(results_list)
    st.dataframe(results_df, use_container_width=True, hide_index=True)

    # CSVå‡ºåŠ›
    csv = results_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name=f"security_check_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
    )


def process_uploaded_files(uploaded_files, vectordb: VectorDatabase):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
    processor = DocumentProcessor()
    all_qa_pairs = []

    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
        for uploaded_file in uploaded_files:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            temp_path = Path(RAW_DATA_DIR) / uploaded_file.name
            temp_path.parent.mkdir(parents=True, exist_ok=True)

            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # å‡¦ç†
            qa_pairs = processor.process_file(str(temp_path))
            all_qa_pairs.extend(qa_pairs)

            st.info(f"âœ“ {uploaded_file.name}: {len(qa_pairs)}ä»¶ã®Q&Aãƒšã‚¢ã‚’æŠ½å‡º")

    if all_qa_pairs:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ä¸­..."):
            count = vectordb.add_qa_pairs(all_qa_pairs)
            st.success(f"ğŸ‰ {count}ä»¶ã®Q&Aãƒšã‚¢ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã—ã¾ã—ãŸ")
            st.rerun()
    else:
        st.warning("Q&Aãƒšã‚¢ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")


def rebuild_database(vectordb: VectorDatabase):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰"""
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰ä¸­..."):
        vectordb.clear_database()

        qa_pairs = process_directory(RAW_DATA_DIR)

        if qa_pairs:
            vectordb.add_qa_pairs(qa_pairs)
            st.success(f"ğŸ‰ {len(qa_pairs)}ä»¶ã®Q&Aãƒšã‚¢ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã—ãŸ")
        else:
            st.warning(f"{RAW_DATA_DIR} ã«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        st.rerun()


if __name__ == "__main__":
    main()
