"""
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯AI - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
å–¶æ¥­å‘ã‘ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨ºæ–­æ”¯æ´ãƒ„ãƒ¼ãƒ«
"""

import os
import sys
from pathlib import Path
import logging
from datetime import datetime

import streamlit as st
import pandas as pd
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from src.document_processor import DocumentProcessor, process_directory
from src.vector_database import VectorDatabase, build_database_from_directory

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è¨­å®š
VECTORDB_PATH = os.getenv("VECTORDB_PATH", "./vectordb")
RAW_DATA_DIR = os.getenv("RAW_DATA_DIR", "./data/raw")
PROCESSED_DATA_DIR = os.getenv("PROCESSED_DATA_DIR", "./data/processed")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯AI",
    page_icon="ğŸ”’",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "vectordb" not in st.session_state:
    st.session_state.vectordb = None
if "qa_history" not in st.session_state:
    st.session_state.qa_history = []


def init_vectordb():
    """ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
    if st.session_state.vectordb is None:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            st.session_state.vectordb = VectorDatabase(
                persist_directory=VECTORDB_PATH, embedding_model=EMBEDDING_MODEL
            )
    return st.session_state.vectordb


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

    st.title("ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯AI")
    st.markdown("å–¶æ¥­å‘ã‘ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨ºæ–­æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ“š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ
        vectordb = init_vectordb()
        stats = vectordb.get_stats()

        st.metric("ç™»éŒ²æ¸ˆã¿Q&Aä»¶æ•°", stats["total_qa_pairs"])

        st.divider()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰")

        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["pdf", "docx", "xlsx", "xls", "txt", "csv"],
            accept_multiple_files=True,
            help="PDFã€Wordã€Excelã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ",
        )

        if uploaded_files:
            if st.button("ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦DBã«è¿½åŠ ", type="primary"):
                process_uploaded_files(uploaded_files, vectordb)

        st.divider()

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä¸€æ‹¬æ§‹ç¯‰
        if st.button("ğŸ”„ data/rawã‹ã‚‰å†æ§‹ç¯‰"):
            rebuild_database(vectordb)

        if stats["total_qa_pairs"] > 0:
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ä¸­..."):
                    vectordb.clear_database()
                    st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                    st.rerun()

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tab1, tab2, tab3 = st.tabs(["ğŸ” è³ªå•æ¤œç´¢", "ğŸ“ ä¸€æ‹¬è³ªå•å‡¦ç†", "ğŸ“Š å±¥æ­´"])

    with tab1:
        single_question_tab(vectordb)

    with tab2:
        batch_question_tab(vectordb)

    with tab3:
        history_tab()


def single_question_tab(vectordb: VectorDatabase):
    """å˜ä¸€è³ªå•ã‚¿ãƒ–"""
    st.header("è³ªå•ã‚’å…¥åŠ›")

    col1, col2 = st.columns([3, 1])

    with col1:
        query = st.text_area(
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            height=150,
            placeholder="ä¾‹: ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–æ–¹æ³•ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        )

    with col2:
        top_k = st.slider("æ¤œç´¢çµæœæ•°", 1, 10, 3)
        score_threshold = st.slider("é¡ä¼¼åº¦é–¾å€¤", 0.0, 1.0, 0.5, 0.05)

    if st.button("ğŸ” æ¤œç´¢", type="primary", disabled=not query):
        search_and_display(vectordb, query, top_k, score_threshold)


def batch_question_tab(vectordb: VectorDatabase):
    """ä¸€æ‹¬è³ªå•å‡¦ç†ã‚¿ãƒ–"""
    st.header("ä¸€æ‹¬è³ªå•å‡¦ç†")

    st.markdown(
        """
    è¤‡æ•°ã®è³ªå•ã‚’ä¸€åº¦ã«å‡¦ç†ã€ã¾ãŸã¯å–¶æ¥­è³‡æ–™ã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    
    **ä½¿ç”¨æ–¹æ³•:**
    - **è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†**: è³ªå•ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¸€æ‹¬ã§å›ç­”ã‚’å–å¾—
    - **è³‡æ–™ãƒã‚§ãƒƒã‚¯**: å–¶æ¥­è³‡æ–™ã®å„æ®µè½ã‚’è‡ªå‹•æŠ½å‡ºã—ã¦ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
    """
    )

    # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
    processing_mode = st.radio(
        "å‡¦ç†ãƒ¢ãƒ¼ãƒ‰",
        ["è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†", "è³‡æ–™ãƒã‚§ãƒƒã‚¯ï¼ˆæ®µè½æŠ½å‡ºï¼‰"],
        help="è³ªå•ãƒªã‚¹ãƒˆ: æ—¢å­˜ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’æ¤œç´¢ | è³‡æ–™ãƒã‚§ãƒƒã‚¯: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æ®µè½ã‚’æŠ½å‡ºã—ã¦ãƒã‚§ãƒƒã‚¯",
    )

    input_method = st.radio("å…¥åŠ›æ–¹æ³•", ["ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"])

    questions = []
    source_name = "æ‰‹å‹•å…¥åŠ›"

    if input_method == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
            batch_text = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ï¼ˆ1è¡Œã«1ã¤ã®è³ªå•ï¼‰",
                height=200,
                placeholder="ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–æ–¹æ³•ã«ã¤ã„ã¦\nã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã®è¨­å®šæ–¹æ³•\n...",
            )
            if batch_text:
                questions = [q.strip() for q in batch_text.split("\n") if q.strip()]
        else:
            batch_text = st.text_area(
                "ãƒã‚§ãƒƒã‚¯ã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›",
                height=200,
                placeholder="å–¶æ¥­è³‡æ–™ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚æ®µè½ã”ã¨ã«è‡ªå‹•åˆ†å‰²ã—ã¦ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚",
            )
            if batch_text:
                # æ®µè½ã«åˆ†å‰²ï¼ˆç©ºè¡Œã§åŒºåˆ‡ã‚‹ï¼‰
                paragraphs = [
                    p.strip() for p in batch_text.split("\n\n") if len(p.strip()) > 20
                ]
                if not paragraphs:
                    # æ”¹è¡Œã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
                    paragraphs = [
                        p.strip() for p in batch_text.split("\n") if len(p.strip()) > 20
                    ]
                questions = paragraphs

    else:
        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["csv", "xlsx", "xls", "pdf", "docx", "txt"],
            help="CSVã€Excelã€PDFã€Wordã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ",
        )

        if uploaded_file:
            source_name = uploaded_file.name
            file_extension = Path(uploaded_file.name).suffix.lower()

            try:
                if file_extension == ".csv":
                    # CSVå‡¦ç†
                    df = pd.read_csv(uploaded_file)
                    st.write("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
                    st.dataframe(df.head())

                    if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                        question_col = st.selectbox(
                            "è³ªå•ãŒå«ã¾ã‚Œã‚‹åˆ—ã‚’é¸æŠ", df.columns
                        )
                        if question_col:
                            questions = df[question_col].dropna().astype(str).tolist()
                    else:
                        st.info(
                            "è³‡æ–™ãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: å…¨åˆ—ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦æ®µè½ã¨ã—ã¦ãƒã‚§ãƒƒã‚¯ã—ã¾ã™"
                        )
                        all_text = df.to_string(index=False)
                        questions = [
                            line.strip()
                            for line in all_text.split("\n")
                            if len(line.strip()) > 20
                        ]

                elif file_extension in [".xlsx", ".xls"]:
                    # Excelå‡¦ç†
                    df = pd.read_excel(uploaded_file)
                    st.write("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
                    st.dataframe(df.head())

                    if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                        question_col = st.selectbox(
                            "è³ªå•ãŒå«ã¾ã‚Œã‚‹åˆ—ã‚’é¸æŠ", df.columns
                        )
                        if question_col:
                            questions = df[question_col].dropna().astype(str).tolist()
                    else:
                        st.info(
                            "è³‡æ–™ãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: å…¨åˆ—ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦æ®µè½ã¨ã—ã¦ãƒã‚§ãƒƒã‚¯ã—ã¾ã™"
                        )
                        all_text = df.to_string(index=False)
                        questions = [
                            line.strip()
                            for line in all_text.split("\n")
                            if len(line.strip()) > 20
                        ]

                elif file_extension == ".pdf":
                    # PDFå‡¦ç†
                    from pypdf import PdfReader
                    import tempfile

                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(
                        delete=False, suffix=".pdf"
                    ) as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name

                    reader = PdfReader(tmp_path)
                    full_text = ""
                    for page in reader.pages:
                        full_text += page.extract_text() + "\n"

                    os.unlink(tmp_path)  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤

                    st.write(f"ğŸ“„ æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
                    st.text(full_text[:500] + "...")

                    if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                        # è¡Œå˜ä½ã§åˆ†å‰²
                        questions = [
                            line.strip()
                            for line in full_text.split("\n")
                            if len(line.strip()) > 10
                        ]
                    else:
                        # æ®µè½å˜ä½ã§åˆ†å‰²
                        paragraphs = [
                            p.strip()
                            for p in full_text.split("\n\n")
                            if len(p.strip()) > 20
                        ]
                        if not paragraphs:
                            paragraphs = [
                                p.strip()
                                for p in full_text.split("\n")
                                if len(p.strip()) > 20
                            ]
                        questions = paragraphs

                elif file_extension == ".docx":
                    # Wordå‡¦ç†
                    from docx import Document as DocxDocument
                    import tempfile

                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(
                        delete=False, suffix=".docx"
                    ) as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name

                    doc = DocxDocument(tmp_path)
                    paragraphs_text = [
                        para.text.strip()
                        for para in doc.paragraphs
                        if para.text.strip()
                    ]

                    os.unlink(tmp_path)  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤

                    st.write(f"ğŸ“„ æŠ½å‡ºã•ã‚ŒãŸæ®µè½æ•°: {len(paragraphs_text)}")
                    if paragraphs_text:
                        st.write("æœ€åˆã®æ®µè½:")
                        st.text(paragraphs_text[0][:300] + "...")

                    if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                        questions = paragraphs_text
                    else:
                        # é•·ã„æ®µè½ã®ã¿ï¼ˆ20æ–‡å­—ä»¥ä¸Šï¼‰
                        questions = [p for p in paragraphs_text if len(p) > 20]

                elif file_extension == ".txt":
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
                    content = uploaded_file.getvalue().decode("utf-8", errors="ignore")

                    st.write(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
                    st.text(content[:500] + "...")

                    if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                        questions = [
                            line.strip() for line in content.split("\n") if line.strip()
                        ]
                    else:
                        paragraphs = [
                            p.strip()
                            for p in content.split("\n\n")
                            if len(p.strip()) > 20
                        ]
                        if not paragraphs:
                            paragraphs = [
                                p.strip()
                                for p in content.split("\n")
                                if len(p.strip()) > 20
                            ]
                        questions = paragraphs

            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                questions = []

    if questions:
        if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
            st.info(f"ğŸ“ {len(questions)}ä»¶ã®è³ªå•ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸ")
        else:
            st.info(
                f"ğŸ“ {len(questions)}ä»¶ã®æ®µè½ã‚’æŠ½å‡ºã—ã¾ã—ãŸï¼ˆæ©Ÿå¯†æƒ…å ±ãƒã‚§ãƒƒã‚¯å¯¾è±¡ï¼‰"
            )

        col1, col2 = st.columns(2)
        with col1:
            if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                top_k = st.slider("å„è³ªå•ã®æ¤œç´¢çµæœæ•°", 1, 5, 1, key="batch_topk")
            else:
                top_k = st.slider("å„æ®µè½ã®æ¤œç´¢çµæœæ•°", 1, 3, 1, key="batch_topk")
        with col2:
            if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                score_threshold = st.slider(
                    "é¡ä¼¼åº¦é–¾å€¤", 0.0, 1.0, 0.6, 0.05, key="batch_threshold"
                )
            else:
                score_threshold = st.slider(
                    "é¡ä¼¼åº¦é–¾å€¤ï¼ˆæ©Ÿå¯†æƒ…å ±æ¤œå‡ºæ„Ÿåº¦ï¼‰",
                    0.0,
                    1.0,
                    0.4,
                    0.05,
                    key="batch_threshold",
                    help="ä½ã„ã»ã©å¹…åºƒããƒã‚§ãƒƒã‚¯ã€é«˜ã„ã»ã©å³å¯†ã«ãƒã‚§ãƒƒã‚¯",
                )

        if st.button("ğŸš€ ä¸€æ‹¬æ¤œç´¢", type="primary"):
            batch_search_and_display(
                vectordb,
                questions,
                top_k,
                score_threshold,
                source_name,
                processing_mode,
            )


def history_tab():
    """å±¥æ­´ã‚¿ãƒ–"""
    st.header("æ¤œç´¢å±¥æ­´")

    if not st.session_state.qa_history:
        st.info("ã¾ã æ¤œç´¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # å±¥æ­´ã‚’DataFrameã«å¤‰æ›
    history_df = pd.DataFrame(st.session_state.qa_history)

    st.dataframe(history_df, use_container_width=True, hide_index=True)

    # CSVå‡ºåŠ›
    if st.button("ğŸ“¥ å±¥æ­´ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
        csv = history_df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button(
            label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"security_check_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
        )

    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.qa_history = []
        st.rerun()


def search_and_display(
    vectordb: VectorDatabase, query: str, top_k: int, score_threshold: float
):
    """æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’è¡¨ç¤º"""
    with st.spinner("æ¤œç´¢ä¸­..."):
        results = vectordb.search(query, top_k=top_k, score_threshold=score_threshold)

    if not results:
        st.warning("è©²å½“ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è³ªå•ã‚’å¤‰ãˆã¦è©¦ã—ã¦ãã ã•ã„ã€‚")
        return

    st.success(f"âœ… {len(results)}ä»¶ã®å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

    for i, result in enumerate(results, 1):
        with st.expander(
            f"ğŸ“„ å›ç­” {i} - é¡ä¼¼åº¦: {result['score']:.2%}", expanded=(i == 1)
        ):
            st.markdown(f"**è³ªå•:** {result['question']}")
            st.markdown(f"**å›ç­”:**")
            st.info(result["answer"])
            st.caption(f"å‡ºå…¸: {result['source']}")

            # å±¥æ­´ã«è¿½åŠ 
            st.session_state.qa_history.append(
                {
                    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "æ¤œç´¢ã‚¯ã‚¨ãƒª": query,
                    "ãƒãƒƒãƒã—ãŸè³ªå•": result["question"],
                    "å›ç­”": result["answer"],
                    "é¡ä¼¼åº¦": f"{result['score']:.2%}",
                    "å‡ºå…¸": result["source"],
                }
            )


def batch_search_and_display(
    vectordb: VectorDatabase,
    questions: list,
    top_k: int,
    score_threshold: float,
    source_name: str = "æ‰‹å‹•å…¥åŠ›",
    processing_mode: str = "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†",
):
    """ä¸€æ‹¬æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    results_list = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, question in enumerate(questions):
        status_text.text(f"å‡¦ç†ä¸­: {i+1}/{len(questions)}")
        progress_bar.progress((i + 1) / len(questions))

        results = vectordb.search(
            question, top_k=top_k, score_threshold=score_threshold
        )

        if results:
            best_result = results[0]

            # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦è¡¨ç¤ºé …ç›®ã‚’å¤‰æ›´
            if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                result_item = {
                    "å…ƒã®è³ªå•/ãƒ†ã‚­ã‚¹ãƒˆ": question[:200]
                    + ("..." if len(question) > 200 else ""),
                    "ãƒãƒƒãƒã—ãŸè³ªå•": best_result["question"],
                    "å›ç­”": best_result["answer"][:300]
                    + ("..." if len(best_result["answer"]) > 300 else ""),
                    "é¡ä¼¼åº¦": f"{best_result['score']:.2%}",
                    "å‡ºå…¸": best_result["source"],
                }
            else:  # è³‡æ–™ãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
                result_item = {
                    "ãƒã‚§ãƒƒã‚¯å¯¾è±¡æ®µè½": question[:200]
                    + ("..." if len(question) > 200 else ""),
                    "é¡ä¼¼ã™ã‚‹æ—¢çŸ¥ã®è³ªå•": best_result["question"],
                    "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦³ç‚¹": best_result["answer"][:300]
                    + ("..." if len(best_result["answer"]) > 300 else ""),
                    "é–¢é€£åº¦": f"{best_result['score']:.2%}",
                    "å‚ç…§å…ƒ": best_result["source"],
                }

            results_list.append(result_item)

            # å±¥æ­´ã«è¿½åŠ 
            st.session_state.qa_history.append(
                {
                    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "å‡¦ç†ãƒ¢ãƒ¼ãƒ‰": processing_mode,
                    "å…¥åŠ›å…ƒ": source_name,
                    "æ¤œç´¢ã‚¯ã‚¨ãƒª": question[:100],
                    "ãƒãƒƒãƒã—ãŸè³ªå•": best_result["question"],
                    "å›ç­”": best_result["answer"],
                    "é¡ä¼¼åº¦": f"{best_result['score']:.2%}",
                    "å‡ºå…¸": best_result["source"],
                }
            )
        else:
            if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
                result_item = {
                    "å…ƒã®è³ªå•/ãƒ†ã‚­ã‚¹ãƒˆ": question[:200]
                    + ("..." if len(question) > 200 else ""),
                    "ãƒãƒƒãƒã—ãŸè³ªå•": "è©²å½“ãªã—",
                    "å›ç­”": "è©²å½“ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                    "é¡ä¼¼åº¦": "0%",
                    "å‡ºå…¸": "-",
                }
            else:
                result_item = {
                    "ãƒã‚§ãƒƒã‚¯å¯¾è±¡æ®µè½": question[:200]
                    + ("..." if len(question) > 200 else ""),
                    "é¡ä¼¼ã™ã‚‹æ—¢çŸ¥ã®è³ªå•": "è©²å½“ãªã—",
                    "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦³ç‚¹": "æ—¢çŸ¥ã®è³ªå•ã«è©²å½“ãªã—ã€‚æ–°è¦ã®å†…å®¹ã¾ãŸã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾è±¡å¤–ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                    "é–¢é€£åº¦": "0%",
                    "å‚ç…§å…ƒ": "-",
                }

            results_list.append(result_item)

    status_text.empty()
    progress_bar.empty()

    if processing_mode == "è³ªå•ãƒªã‚¹ãƒˆå‡¦ç†":
        st.success(f"âœ… {len(questions)}ä»¶ã®è³ªå•ã‚’å‡¦ç†ã—ã¾ã—ãŸ")
    else:
        st.success(f"âœ… {len(questions)}ä»¶ã®æ®µè½ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸ")
        st.info(
            "ğŸ’¡ ãƒ’ãƒ³ãƒˆ: é–¢é€£åº¦ãŒé«˜ã„é …ç›®ã¯ã€æ—¢çŸ¥ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è³ªå•ã«é¡ä¼¼ã—ã¦ã„ã¾ã™ã€‚é–¢é€£åº¦ãŒä½ã„é …ç›®ã¯æ–°è¦ã®å†…å®¹ã‹ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾è±¡å¤–ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        )

    # çµæœã‚’DataFrameã§è¡¨ç¤º
    results_df = pd.DataFrame(results_list)
    st.dataframe(results_df, use_container_width=True, hide_index=True)

    # CSVå‡ºåŠ›
    csv = results_df.to_csv(index=False, encoding="utf-8-sig")

    download_filename = (
        f"security_check_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    )
    if processing_mode == "è³‡æ–™ãƒã‚§ãƒƒã‚¯ï¼ˆæ®µè½æŠ½å‡ºï¼‰":
        download_filename = (
            f"document_security_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )

    st.download_button(
        label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name=download_filename,
        mime="text/csv",
    )


def process_uploaded_files(uploaded_files, vectordb: VectorDatabase):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
    processor = DocumentProcessor()
    all_qa_pairs = []

    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
        for uploaded_file in uploaded_files:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            temp_path = Path(RAW_DATA_DIR) / uploaded_file.name
            temp_path.parent.mkdir(parents=True, exist_ok=True)

            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # å‡¦ç†
            qa_pairs = processor.process_file(str(temp_path))
            all_qa_pairs.extend(qa_pairs)

            st.info(f"âœ“ {uploaded_file.name}: {len(qa_pairs)}ä»¶ã®Q&Aãƒšã‚¢ã‚’æŠ½å‡º")

    if all_qa_pairs:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ä¸­..."):
            count = vectordb.add_qa_pairs(all_qa_pairs)
            st.success(f"ğŸ‰ {count}ä»¶ã®Q&Aãƒšã‚¢ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã—ã¾ã—ãŸ")
            st.rerun()
    else:
        st.warning("Q&Aãƒšã‚¢ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")


def rebuild_database(vectordb: VectorDatabase):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰"""
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰ä¸­..."):
        vectordb.clear_database()

        qa_pairs = process_directory(RAW_DATA_DIR)

        if qa_pairs:
            vectordb.add_qa_pairs(qa_pairs)
            st.success(f"ğŸ‰ {len(qa_pairs)}ä»¶ã®Q&Aãƒšã‚¢ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã—ãŸ")
        else:
            st.warning(f"{RAW_DATA_DIR} ã«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        st.rerun()


if __name__ == "__main__":
    main()
